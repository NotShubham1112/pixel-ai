# Emotion Recognition LLM for Raspberry Pi
## Child-Friendly AI Companion for AI Mirror Project

A complete, production-ready pipeline for building, training, and deploying an emotion-aware, offline LLM optimized for Raspberry Pi 5. Designed specifically for children aged 5-16 with comprehensive safety features and ethical guidelines.

---

## ğŸ¯ Project Overview

### Purpose
Create an AI companion for an **Emotion Recognition AI Mirror** that:
- âœ… Recognizes facial expressions and emotional context
- âœ… Understands age-appropriate conversation
- âœ… Responds with safe, friendly, educational answers
- âœ… Operates **100% offline** on Raspberry Pi
- âœ… Includes comprehensive safety filters
- âœ… Respects privacy with local-only data storage

### Key Features
- **Emotion-Aware**: Adapts responses based on detected emotions (happy, sad, angry, etc.)
- **Age-Appropriate**: Adjusts language complexity for ages 5-16
- **Safety-First**: Multi-layer content filtering and moderation
- **Privacy-Preserving**: All data stored locally, no cloud dependencies
- **Memory System**: Ethical, consent-based conversation context
- **Offline**: Fully functional without internet connection
- **Optimized**: Runs efficiently on Raspberry Pi 5 (4GB/8GB)

---

## ğŸ“‹ Table of Contents

1. [Quick Start](#quick-start)
2. [System Architecture](#system-architecture)
3. [Installation](#installation)
4. [Training Pipeline](#training-pipeline)
5. [Deployment](#deployment)
6. [Usage Examples](#usage-examples)
7. [Safety & Ethics](#safety--ethics)
8. [Performance](#performance)
9. [Troubleshooting](#troubleshooting)
10. [Contributing](#contributing)

---

## ğŸš€ Quick Start

### Prerequisites
- **Training**: GPU with 16GB+ VRAM (or Google Colab)
- **Deployment**: Raspberry Pi 5 (8GB recommended)
- **Python**: 3.10+
- **Storage**: ~2GB for model and dependencies

### 5-Minute Setup (Training)

```bash
# 1. Clone and install dependencies
git clone <your-repo>
cd llmemo
pip install -r requirements_training.txt

# 2. Generate training dataset
python generate_dataset.py --size 50000 --output training_dataset.json

# 3. Train with QLoRA
python train_lora.py --dataset training_dataset.json --epochs 3

# 4. Quantize for Raspberry Pi
python quantize_model.py --model ./emotion-llm-finetuned --method Q4_K_M

# 5. Deploy to Pi (see deploy_raspberry_pi.md)
```

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AI Mirror Application                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Camera â†’ Emotion Detection â†’ Voice Input â†’ LLM â†’ TTS       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Inference Engine (This Project)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Safety Filterâ”‚  â”‚ Memory Mgr   â”‚  â”‚ Prompt Gen   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                              â†“                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         llama.cpp (Quantized Model)                  â”‚   â”‚
â”‚  â”‚         Qwen2.5-0.5B + LoRA Fine-tuning              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

| Component | Purpose | File |
|-----------|---------|------|
| **Model Config** | Base model and schema definitions | `model_config.json` |
| **Prompt Template** | Emotion-aware prompt generation | `emotion_prompt_template.py` |
| **Dataset Generator** | Synthetic training data creation | `generate_dataset.py` |
| **Training Script** | QLoRA fine-tuning pipeline | `train_lora.py` |
| **Quantization** | GGUF conversion for Pi | `quantize_model.py` |
| **Safety Filter** | Content moderation | `safety_filter.py` |
| **Memory Manager** | Conversation context | `memory_manager.py` |
| **Inference Engine** | Main inference wrapper | `inference_engine.py` |

---

## ğŸ’» Installation

### Training Environment (GPU Machine / Colab)

```bash
# Install PyTorch with CUDA
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# Install training dependencies
pip install -r requirements_training.txt

# Verify installation
python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
```

### Raspberry Pi Environment

See detailed instructions in [`deploy_raspberry_pi.md`](deploy_raspberry_pi.md)

```bash
# Quick Pi setup
sudo apt update && sudo apt install -y build-essential cmake git python3-pip
git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp && make -j4
```

---

## ğŸ“ Training Pipeline

### 1. Dataset Generation

```bash
# Generate 50k examples (balanced across emotions and ages)
python generate_dataset.py --size 50000 --output training_dataset.json

# Validate dataset
python generate_dataset.py --validate --output training_dataset.json
```

**Dataset Structure:**
- 50k-200k examples
- 8 emotion categories (happy, sad, angry, surprised, neutral, confused, excited, worried)
- 4 age groups (5-7, 8-10, 11-13, 14-16)
- Safety-filtered and age-appropriate

### 2. Model Training

```bash
# Train with default settings (recommended)
python train_lora.py --dataset training_dataset.json

# Custom training
python train_lora.py \
  --dataset training_dataset.json \
  --base-model Qwen/Qwen2.5-0.5B-Instruct \
  --epochs 3 \
  --batch-size 4 \
  --learning-rate 2e-4 \
  --output ./emotion-llm-finetuned
```

**Training Configuration:**
- **Base Model**: Qwen2.5-0.5B-Instruct (500M parameters)
- **Method**: QLoRA (4-bit quantization during training)
- **LoRA Rank**: 16, Alpha: 32
- **Batch Size**: 4 (effective: 16 with gradient accumulation)
- **Epochs**: 3-5
- **Learning Rate**: 2e-4 with cosine scheduler
- **Training Time**: ~2-4 hours on RTX 3090

### 3. Model Quantization

```bash
# Quantize to INT4 for Raspberry Pi
python quantize_model.py \
  --model ./emotion-llm-finetuned \
  --method Q4_K_M \
  --output ./quantized_models

# Compare all quantization methods
python quantize_model.py --model ./emotion-llm-finetuned --all
```

**Quantization Options:**
- **Q4_K_M**: 4-bit, ~400MB (recommended for Pi 5)
- **Q4_K_S**: 4-bit, ~350MB (for 4GB Pi)
- **Q5_K_M**: 5-bit, ~500MB (better quality, 8GB Pi)
- **Q8_0**: 8-bit, ~800MB (highest quality)

---

## ğŸš¢ Deployment

### Raspberry Pi 5 Deployment

See complete guide: [`deploy_raspberry_pi.md`](deploy_raspberry_pi.md)

**Quick Deployment:**

```bash
# 1. Copy model to Pi
scp quantized_models/model-q4_k_m.gguf pi@raspberrypi.local:~/emotion-llm/

# 2. Copy Python scripts
scp *.py pi@raspberrypi.local:~/emotion-llm/

# 3. Test inference on Pi
python inference_engine.py \
  --model model-q4_k_m.gguf \
  --emotion happy \
  --age 9 \
  --question "Why is the sky blue?"
```

---

## ğŸ“ Usage Examples

### Basic Inference

```python
from inference_engine import InferenceEngine

# Initialize engine
engine = InferenceEngine(model_path="model-q4_k_m.gguf")

# Generate response
result = engine.generate_response(
    emotion="happy",
    confidence=0.85,
    age_group=9,
    question="Why is the sky blue?",
    use_memory=True
)

print(result["response"])
# Output: "Great question! The sky looks blue because of something called 'scattering.'..."
```

### With Memory

```python
from memory_manager import MemoryManager

# Initialize memory
memory = MemoryManager()
memory.give_consent(True)  # Required for storing preferences
memory.set_user_profile(name="Alex", age=9, favorite_color="blue")

# Memory is automatically used by inference engine
result = engine.generate_response(
    emotion="excited",
    confidence=0.92,
    age_group=9,
    question="Tell me about space!",
    use_memory=True
)
# Response will personalize: "Hi Alex! I know you love learning..."
```

### Safety Filtering

```python
from safety_filter import SafetyFilter

filter = SafetyFilter()

# Check input safety
result = filter.filter_input("How do I make a weapon?", age=10)
if not result.is_safe:
    print(filter.get_refusal_response(result.severity, 10))
    # Output: "I can't help with that question. Please ask a parent or teacher instead!"
```

### Example Conversations

See [`example_conversations.json`](example_conversations.json) for 11 complete conversation examples demonstrating:
- Emotion-aware responses
- Age-appropriate language
- Memory integration
- Safety filtering
- Multi-turn conversations

---

## ğŸ›¡ï¸ Safety & Ethics

### Safety Features
âœ… **Multi-layer Content Filtering**: Forbidden keywords, topic detection  
âœ… **Age-Appropriate Responses**: Language complexity adjusted by age  
âœ… **Automatic Redirection**: Medical, legal, crisis topics â†’ adults  
âœ… **Response Validation**: Output checked before delivery  
âœ… **Uncertainty Statements**: AI admits when unsure  

### Privacy Protection
âœ… **Local-Only Storage**: No cloud, no external servers  
âœ… **Parental Consent**: Required for memory features  
âœ… **Data Minimization**: Only essential data stored  
âœ… **Easy Deletion**: One-click data removal  
âœ… **Encryption**: User data encrypted at rest  

### Ethical Guidelines
See complete documentation: [`ethical_guidelines.md`](ethical_guidelines.md)

**Key Principles:**
1. Child safety first
2. Transparency (AI identifies itself)
3. Privacy protection
4. Educational purpose only
5. Not a replacement for human interaction

---

## âš¡ Performance

### Raspberry Pi 5 Benchmarks

| Metric | Target | Actual (Q4_K_M) |
|--------|--------|-----------------|
| Inference Latency | <2s | ~1.5s |
| Memory Usage | <3GB | ~2.2GB |
| Model Size | <500MB | ~400MB |
| CPU Usage | <80% | ~65% |
| Tokens/Second | >20 | ~25 |

### Optimization Tips
- Use Q4_K_S for 4GB Pi models
- Enable active cooling for sustained use
- Reduce `max_tokens` to 200 for faster responses
- Use 4 threads (`-t 4`) for optimal performance
- Close background applications

---

## ğŸ› Troubleshooting

### Common Issues

**Slow Inference (>3 seconds)**
- Use smaller quantization (Q4_K_S)
- Reduce max_tokens
- Check CPU temperature (thermal throttling)
- Ensure active cooling

**Out of Memory**
- Increase swap space
- Use 8GB Pi 5 model
- Reduce context window (`-c 1024`)
- Close other applications

**llama.cpp Not Found**
- Verify build: `cd llama.cpp && make clean && make -j4`
- Check path in `inference_engine.py`
- Try alternative paths (see `deploy_raspberry_pi.md`)

**Safety Filter Too Strict**
- Review `safety_filter.py` keyword lists
- Adjust severity levels
- Add exceptions for educational terms

---

## ğŸ“š File Structure

```
llmemo/
â”œâ”€â”€ model_config.json              # Model configuration
â”œâ”€â”€ dataset_schema.json            # Training data schema
â”œâ”€â”€ emotion_prompt_template.py     # Prompt engineering
â”œâ”€â”€ generate_dataset.py            # Dataset generation
â”œâ”€â”€ sample_dataset.json            # 20 curated examples
â”œâ”€â”€ train_lora.py                  # QLoRA training
â”œâ”€â”€ requirements_training.txt      # Training dependencies
â”œâ”€â”€ quantize_model.py              # Model quantization
â”œâ”€â”€ safety_filter.py               # Content moderation
â”œâ”€â”€ memory_manager.py              # Conversation memory
â”œâ”€â”€ inference_engine.py            # Main inference wrapper
â”œâ”€â”€ deploy_raspberry_pi.md         # Pi deployment guide
â”œâ”€â”€ example_conversations.json     # Usage examples
â”œâ”€â”€ ethical_guidelines.md          # Safety & ethics
â””â”€â”€ README.md                      # This file
```

---

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- Additional emotion categories
- More diverse training examples
- Better safety filters
- Performance optimizations
- Multi-language support
- Integration examples

---

## ğŸ“„ License

This project is provided for educational purposes. Please ensure compliance with:
- COPPA (Children's Online Privacy Protection Act)
- GDPR-K (GDPR for children)
- Local children's privacy regulations

---

## âš ï¸ Disclaimer

This AI system is:
- âœ… An educational tool and companion
- âŒ NOT a replacement for human interaction
- âŒ NOT a medical, therapeutic, or counseling service
- âŒ NOT suitable for emergency situations
- âŒ NOT guaranteed to be 100% accurate

**Parental supervision required. Not a substitute for professional advice.**

---

## ğŸ“ Support

For issues, questions, or feedback:
1. Check [`deploy_raspberry_pi.md`](deploy_raspberry_pi.md) for deployment issues
2. Review [`example_conversations.json`](example_conversations.json) for usage patterns
3. Consult [`ethical_guidelines.md`](ethical_guidelines.md) for safety questions

---

## ğŸ™ Acknowledgments

- **Base Model**: Qwen2.5-0.5B by Alibaba Cloud
- **Inference Engine**: llama.cpp by ggerganov
- **Training Framework**: Hugging Face Transformers & PEFT

---

**Built with â¤ï¸ for safe, educational AI interactions with children.**

*Version 1.0.0 | Last Updated: 2026-01-09*
